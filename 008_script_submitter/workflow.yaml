jobs:
  main:
    steps:
      - name: Write Script
        if: ${{ inputs.input_method === TEXT }}
        run: |
          echo '${{ inputs.script_text }}' > script.sh
          chmod +x script.sh
      - name: Test workflow launch context
        run: |
          echo "==========What does tilde do?=========="
          echo Local test
          echo ~
          echo Remote test
          ssh -o StrictHostKeyChecking=no ${{ inputs.resource.ip }} echo ~
          echo "==========What is my local env?========"
          env
          echo "==========What is my remote env?======="
          ssh -o StrictHostKeyChecking=no ${{ inputs.resource.ip }} env
          echo "==========What happens if I access my resource?======="
          echo ${{ inputs.resource }}
          echo "==========Can I access inputs.sh?==========="
          source inputs.sh
          env | grep resource
      - name: Transfer Script to Cluster
        if: ${{  inputs.input_method === TEXT || inputs.input_method === WORKSPACE_PATH }}
        run: |
          source inputs.sh
          ssh -o StrictHostKeyChecking=no ${{ inputs.resource.ip }} mkdir -p /home/${resource_username}/pw/jobs/script_submitter/tmp
          scp script.sh ${{ inputs.resource.ip }}:/home/${resource_username}/pw/jobs/script_submitter/tmp
      - name: Run Script in Controller Node
        if: ${{ inputs.jobschedulertype === CONTROLLER }}
        run: |
          source inputs.sh
          ssh -o StrictHostKeyChecking=no ${{ inputs.resource.ip }} /home/${resource_username}/pw/jobs/script_submitter/tmp/script.sh
      - name: Submit Script to SLURM Partition
        if: ${{ inputs.jobschedulertype === SLURM }}
        run: |
          set -x
          source inputs.sh
          jobid=$(ssh -o StrictHostKeyChecking=no ${{ inputs.resource.ip }} sbatch /home/${resource_username}/pw/jobs/script_submitter/tmp/script.sh  | tail -1 | awk -F ' ' '{print $4}')
          # Check if jobid is empty and exit with error if true
          if [[ -z "${jobid}" ]]; then
              echo "Error: Job submission failed. jobid is empty." >&2
              exit 1
          fi
          echo jobid=${jobid} >> $OUTPUTS
      - name: Submit Script to PBS Queue
        if: ${{ inputs.jobschedulertype === PBS }}
        run: |
          source inputs.sh
          jobid=$(ssh -o StrictHostKeyChecking=no ${{ inputs.resource.ip }} qsub /home/${resource_username}/pw/script_submitter/tmp/script.sh)
          # Check if jobid is empty and exit with error if true
          if [[ -z "${jobid}" ]]; then
              echo "Error: Job submission failed. jobid is empty." >&2
              exit 1
          fi
          echo jobid=${jobid} >> $OUTPUTS
      - name: Wait for SLURM Job
        env:
          sshcmd: ssh -o StrictHostKeyChecking=no ${{ inputs.resource.ip }}
          jobid: ${{ needs.main.outputs.jobid }}
        if: ${{ inputs.wait_for_job === true && inputs.jobschedulertype === SLURM }}
        run: |

          get_slurm_job_status() {
            # Get the header line to determine the column index corresponding to the job status
            if [ -z "${SQUEUE_HEADER}" ]; then
              export SQUEUE_HEADER="$(eval "$sshcmd squeue" | awk 'NR==1')"
            fi
            status_column=$(echo "${SQUEUE_HEADER}" | awk '{ for (i=1; i<=NF; i++) if ($i ~ /^S/) { print i; exit } }')
            status_response=$(eval $sshcmd squeue | grep "\<${jobid}\>")
            echo "${SQUEUE_HEADER}"
            echo "${status_response}"
            export job_status=$(echo ${status_response} | awk -v id="${jobid}" -v col="$status_column" '{print $col}')
          }

          while true; do
            sleep 15
            # squeue won't give you status of jobs that are not running or waiting to run
            get_slurm_job_status
            # If job status is empty job is no longer running
            if [ -z "${job_status}" ]; then
              job_status=$($sshcmd sacct -j ${jobid}  --format=state | tail -n1)
              break
            fi
          done

          echo "completed=true" >> $OUTPUTS
        cleanup: |
          if [[ "${{ needs.main.outputs.completed }}" == "true" ]]; then
              exit 0
          fi

          echo Cancelling Job
          $sshcmd scancel ${{ needs.main.outputs.jobid }}
      - name: Wait for PBS Job
        env:
          sshcmd: ssh -o StrictHostKeyChecking=no ${{ inputs.resource.ip }}
          jobid: ${{ needs.main.outputs.jobid }}
        if: ${{ inputs.wait_for_job === true && inputs.jobschedulertype === PBS }}
        run: |

          get_pbs_job_status() {
            # Get the header line to determine the column index corresponding to the job status
            if [ -z "${QSTAT_HEADER}" ]; then
              export QSTAT_HEADER="$(eval "$sshcmd qstat" | awk 'NR==1')"
            fi
            status_response=$(eval $sshcmd qstat 2>/dev/null | grep "\<${jobid}\>")
            echo "${QSTAT_HEADER}"
            echo "${status_response}"
            export job_status="$(eval $sshcmd qstat -f ${jobid} 2>/dev/null  | grep job_state | cut -d'=' -f2 | tr -d ' ')"
          }

          while true; do
            sleep 15
            get_pbs_job_status
            if [[ "${job_status}" == "C" ]]; then
                break
            elif [ -z "${job_status}" ]; then
                break
            fi
          done

          echo "completed=true" >> $OUTPUTS
        cleanup: |
          if [[ "${{ needs.main.outputs.completed }}" == "true" ]]; then
              exit 0
          fi

          echo Cancelling Job
          $sshcmd qdel ${{ needs.main.outputs.jobid }}
'on':
  execute:
    inputs:
      header:
        type: header
        text: Starter Local Workflow
        size: 20
      resource:
        type: compute-clusters
        label: Resource
      jobschedulertype:
        type: dropdown
        label: Select Controller, SLURM Partition or PBS Queue
        tooltip: Job will submitted using SSH, sbatch or qsub, respectively
        options:
          - label: Controller or Login Node
            value: CONTROLLER
          - label: SLURM Partition
            value: SLURM
          - label: PBS Queue
            value: PBS
        default: CONTROLLER
      wait_for_job:
        label: Wait for the PBS job or fire and forget?
        type: boolean
        default: true
        hidden: ${{ inputs.jobschedulertype === CONTROLLER }}
        ignore: ${{ .hidden }}
        optional: ${{ .hidden }}
        tooltip: If yes is selected, the PW job waits for the SLURM or PBS job to complete while continuously monitoring its status and the possibility to cancel the SLURM or PBS job when the PW job is canceled
      input_method:
        label: Select Method to Input Script
        type: dropdown
        tooltip: This script is submitted to the selected resource
        default: TEXT
        options:
          - label: Type your script
            value: TEXT
          - label: Path to the script in the user workspace
            value: WORKSPACE_PATH
          - label: Path to the script in the resource
            value: RESOURCE_PATH
      script_text:
        label: Type your script
        type: string
        textarea: true
        default: '#!/bin/bash'
        tooltip: Type or copy paste the script that is submitted to the selected resource
        hidden: ${{inputs.input_method != "TEXT"}}
      workspace_script_path:
        label: Path to the script in the user workspace
        tooltip: Use an absolute path if the script is not in the workflow directory
        type: string
        default: /path/to/script
        hidden: ${{inputs.input_method != "WORKSPACE_PATH"}}
      resource_script_path:
        label: Path to the script in the resource
        tooltip: Use an absolute path if the script is not in the workflow directory
        type: string
        default: /path/to/script
        hidden: ${{inputs.input_method != "RESOURCE_PATH"}}
