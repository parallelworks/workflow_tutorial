permissions:
  - '*'
jobs:
  auth:
    steps:
      - name: Authenticate kubectl
        run: pw kube auth ${{ inputs.k8s.cluster }}
  k8s_deployment:
    needs:
      - auth
    steps:
      - name: Defining job id
        run: |
          job_number=$(pwd | rev | cut -d "/" -f1 | rev)
          echo "export job_number=${job_number}" > job.info
          workflow_name=$(pwd | rev | cut -d "/" -f2 | rev)
          echo "export workflow_name=${workflow_name}" >> job.info
          job_id="${PW_USER}-${workflow_name}-${job_number}-$(date +%s)"
          echo "job_id=${job_id}" | tee -a $OUTPUTS
      - name: Add training script to config map
        env:
          configmap_name: train-script-${{ needs.k8s_deployment.outputs.job_id }}
        run: |
          set -xe
          trap './notify.sh create-configmap 1' ERR
          sed -i "s/__num_epochs__/${{ inputs.model.num_epochs }}/g" train-script.py
          sed -i "s/__lr__/${{ inputs.model.lr }}/g" train-script.py
          sed -i "s/__batch_size__/${{ inputs.model.batch_size }}/g" train-script.py
          sed -i "s|__save_path__|${{ inputs.model.save_path }}|g" train-script.py
          kubectl create configmap ${configmap_name} --from-file=train-script.py -n ${{ inputs.k8s.namespace }}
        cleanup: kubectl delete configmap ${configmap_name} -n ${{ inputs.k8s.namespace }}
      - name: Apply PVC
        env:
          pvc_name: model-storage-${{ needs.k8s_deployment.outputs.job_id }}
        run: |
          set -xe
          trap './notify.sh apply-pvc 2' ERR
          # Create pvc.yaml configuration
          cat > pvc.yaml <<HERE
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: ${pvc_name}
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage:  ${{ inputs.k8s.pvc_storage }}
          HERE

          # Apply pvc.yaml configuration
          kubectl apply -f pvc.yaml -n ${{ inputs.k8s.namespace }}
        cleanup: kubectl delete -f pvc.yaml -n ${{ inputs.k8s.namespace }}
      - name: Apply training job
        env:
          train_job_name: mnist-train-${{ needs.k8s_deployment.outputs.job_id }}
          pvc_name: model-storage-${{ needs.k8s_deployment.outputs.job_id }}
          configmap_name: train-script-${{ needs.k8s_deployment.outputs.job_id }}
        run: |
          set -xe
          trap './notify.sh apply-train-job 3' ERR
          model_save_path_dir=$(dirname ${{ inputs.model.save_path }})
          # Create train-job.yaml configuration
          cat > train-job.yaml <<HERE
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: ${train_job_name}
          spec:
            template:
              spec:
                runtimeClassName: nvidia
                containers:
                - name: trainer
                  image: pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime
                  command: ["python", "/scripts/train-script.py"]
                  resources:
                    requests:
                      cpu: "${{ inputs.k8s.cpu_request }}"          # Request 1 CPU core
                      memory: "${{ inputs.k8s.memory_request }}"     # Request 2 GiB of memory
                    limits:
                      nvidia.com/gpu: ${{ inputs.k8s.gpu_limit }}
                  volumeMounts:
                  - mountPath: "${model_save_path_dir}"
                    name: ${pvc_name}
                  - mountPath: "/scripts"
                    name: script-volume
                volumes:
                - name:  ${pvc_name}
                  persistentVolumeClaim:
                    claimName:  ${pvc_name}
                - name: script-volume
                  configMap:
                    name: ${configmap_name}
                restartPolicy: Never
            backoffLimit: 2
          HERE

          # Apply train-job.yaml configuration
          kubectl apply -f train-job.yaml -n ${{ inputs.k8s.namespace }}
        cleanup: kubectl delete -f train-job.yaml -n ${{ inputs.k8s.namespace }}
      - name: Wait for pod to start
        env:
          train_job_name: mnist-train-${{ needs.k8s_deployment.outputs.job_id }}
          namespace: ${{ inputs.k8s.namespace }}
        run: |
          source k8s_libs.sh
          trap './notify.sh wait-for-pod 4' ERR

          pod_name=$(get_pod_name_from_job_name "${namespace}" "${train_job_name}")
          if [ $? -eq 0 ]; then
            phase=$(wait_for_pod "${namespace}" "${pod_name}")
            if [ $? -eq 0 ]; then
              echo "Pod ${pod_name} state is ${phase}"
            else
              echo "Pod ${pod_name} failed to reach Running state" >&2
              exit 1
            fi
          else
            echo "Failed to get pod name" >&2
            exit 1
          fi
      - name: Wait for job to finish
        env:
          train_job_name: mnist-train-${{ needs.k8s_deployment.outputs.job_id }}
          namespace: ${{ inputs.k8s.namespace }}
        run: |
          source k8s_libs.sh

          # Stream logs in background
          kubectl logs -n ${namespace} -f job/${train_job_name} &
          LOGS_PID=$!
          # Set trap to kill logs process on exit
          trap 'kill $LOGS_PID 2>/dev/null' EXIT

          echo "Waiting for job ${train_job_name} to finish..."

          status=$(wait_for_job_completion ${namespace} ${train_job_name})
          exit_code=$?
          if [ $exit_code -eq 0 ]; then
            echo "Job finished successfully with status: $status"
          else
            echo "Job did not succeed with status: $status"
            ./notify.sh wait-for-job 5
            exit 1
          fi
      - name: Print logs
        env:
          train_job_name: mnist-train-${{ needs.k8s_deployment.outputs.job_id }}
        run: |
          # Get the pod name associated with the job
          pod_name=$(kubectl get pod -n ${{ inputs.k8s.namespace }} -l job-name=${train_job_name} -o jsonpath="{.items[0].metadata.name}")

          # Check if pod_name is empty (i.e., no pod found)
          if [ -z "$pod_name" ]; then
            echo "Error: No pod found for job ${train_job_name}"
            ./notify.sh print-logs 6
            exit 1
          fi

          # Print the pod name
          echo "Pod name: ${pod_name}"

          # Print the logs of the pod
          kubectl logs ${pod_name} -n ${{ inputs.k8s.namespace }}
        cleanup: |
          # Get the pod name associated with the job
          pod_name=$(kubectl get pod -n ${{ inputs.k8s.namespace }} -l job-name=${train_job_name} -o jsonpath="{.items[0].metadata.name}")

          # Delete the pod if it exists
          if [ -n "$pod_name" ]; then
            echo "Cleaning up pod: ${pod_name}"
            kubectl delete pod ${pod_name} --force --grace-period=0 -n ${{ inputs.k8s.namespace }}
          else
            echo "No pod found to cleanup for job ${train_job_name}"
          fi
      - name: Create transfer pod
        env:
          transfer_pod_name: mnist-transfer-${{ needs.k8s_deployment.outputs.job_id }}
          pvc_name: model-storage-${{ needs.k8s_deployment.outputs.job_id }}
        run: |
          set -xe
          trap './notify.sh apply-transfer-pod 8' ERR
          model_save_path_dir=$(dirname ${{ inputs.model.save_path }})
          # Create transfer-pod.yaml configuration
          cat > transfer-pod.yaml <<HERE
          apiVersion: v1
          kind: Pod
          metadata:
            name: ${transfer_pod_name}
          spec:
            containers:
            - name: transfer
              image: pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime
              command: ["sleep", "3600"]
              resources:
                requests:
                  memory: "100Mi"
                  cpu: "500m"
              volumeMounts:
              - mountPath: "${model_save_path_dir}"
                name: ${pvc_name}
            volumes:
            - name: ${pvc_name}
              persistentVolumeClaim:
                claimName: ${pvc_name}
            restartPolicy: Never
          HERE

          # Apply the transfer pod configuration
          kubectl apply -f transfer-pod.yaml -n ${{ inputs.k8s.namespace }}
        cleanup: kubectl delete pod ${transfer_pod_name} --force --grace-period=0 -n ${{ inputs.k8s.namespace }}
      - name: Transfer ML model
        env:
          transfer_pod_name: mnist-transfer-${{ needs.k8s_deployment.outputs.job_id }}
          pvc_name: model-storage-${{ needs.k8s_deployment.outputs.job_id }}
        run: |
          set -xe
          trap './notify.sh transfer-ml-model 9' ERR
          model_save_path_basename=$(basename ${{ inputs.model.save_path }})
          # Wait for the transfer pod to be running
          echo "Waiting for transfer pod to start..."
          if ! kubectl wait -n ${{ inputs.k8s.namespace }} --for=condition=Ready pod/${transfer_pod_name} --timeout=300s; then
            echo "Error: Transfer pod did not start in time."
            exit 1
          fi

          # Copy the model file from the PVC to the local machine
          if ! kubectl cp ${transfer_pod_name}:${{ inputs.model.save_path }} ./${model_save_path_basename} -n ${{ inputs.k8s.namespace }}; then
            echo "Error: Failed to copy model file."
            exit 1
          fi

          echo "Model file transfer completed successfully."
'on':
  execute:
    inputs:
      k8s:
        type: group
        label: Kubernetes
        items:
          cluster:
            label: Kubernetes cluster
            type: kubernetes-clusters
          namespace:
            label: Namespace
            type: kubernetes-namespaces
            clusterName: ${{ inputs.k8s.cluster }}
          gpu_limit:
            label: GPU Limit
            type: number
            default: 1
            min: 0
            max: 2
          cpu_request:
            label: CPU Request
            type: number
            default: 1
          memory_request:
            label: Memory Request
            type: string
            default: 2Gi
          pvc_storage:
            label: PVC Storage
            type: string
            default: 1Gi
      model:
        type: group
        label: ML Model
        items:
          num_epochs:
            label: Number of Epochs
            type: number
            default: 5
            min: 1
            max: 500
          lr:
            label: Learning Rate
            type: number
            default: 0.01
            min: 0
            max: 1
          batch_size:
            label: Batch Size
            type: number
            default: 64
            min: 8
            max: 128
          save_path:
            label: Save path
            type: string
            default: /mnt/model/mnist_cnn.pt
            tooltip: Path to save the trained model parameters
